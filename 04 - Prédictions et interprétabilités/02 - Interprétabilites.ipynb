{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Régression linéaire multiple interpretabilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_int = LinearRegression()\n",
    "model_lr_int.fit(X_train, y_train)\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model_lr_int.coef_\n",
    "})\n",
    "print(\"Coefficients of Linear Regression Model:\")\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_lr = shap.Explainer(model_lr_int, X_test)\n",
    "shap_values_lr = explainer_lr(X_test)\n",
    "shap.initjs()\n",
    "shap.summary_plot(shap_values_lr, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. random forest interpretabilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_rf = model_rf.feature_importances_\n",
    "indices_rf = np.argsort(importances_rf)[::-1]\n",
    "\n",
    "print(\"Feature importances for Random Forest:\")\n",
    "for f in range(X.shape[1]):\n",
    "    print(f\"{X.columns[indices_rf[f]]}: {importances_rf[indices_rf[f]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_lime = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names= X_train.columns, class_names= ['Prix'], mode='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "exp_rf = explainer_lime.explain_instance(X_test.values[i], model_rf.predict)\n",
    "exp_rf.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBOOOST interpretabilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(best_xgb_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_xgb = shap.Explainer(best_xgb_model, X_test)\n",
    "shap_values_xgb = explainer_xgb(X_test)\n",
    "shap.initjs()\n",
    "shap.summary_plot(shap_values_xgb, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Régression Ridge et Lasso intérprétabilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model_ridge.coef_\n",
    "})\n",
    "print(\"Coefficients of ridge Model:\")\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model_lasso.coef_\n",
    "})\n",
    "print(\"Coefficients of lasso Model:\")\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_ridge = shap.Explainer(model_ridge, X_test)\n",
    "shap_values_ridge = explainer_ridge(X_test)\n",
    "shap.initjs()\n",
    "shap.summary_plot(shap_values_ridge, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_lasso = shap.Explainer(model_lasso, X_test)\n",
    "shap_values_lasso = explainer_lasso(X_test)\n",
    "shap.initjs()\n",
    "shap.summary_plot(shap_values_lasso, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modèles d'arbres de décision interprétabilité\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_dt = model_dt.feature_importances_\n",
    "indices_dt = np.argsort(importances_dt)[::-1]\n",
    "\n",
    "print(\"Feature importances for decision tree:\")\n",
    "for f in range(X.shape[1]):\n",
    "    print(f\"{X.columns[indices_dt[f]]}: {importances_dt[indices_dt[f]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 9\n",
    "exp_dt = explainer_lime.explain_instance(X_test.values[i], model_dt.predict)\n",
    "exp_dt.show_in_notebook(show_table=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
